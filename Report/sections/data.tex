In our work, we have used the first version of the MS Marco Dataset (reference bib), which is composed by 100k real Bing questions and human generated answers. The dataset is already partitioned into Training (82326 samples), Validation (10047 samples) and Test (9650 samples). Each partition is organized as a dictionary where the most important keys are the following:
\begin{itemize}
    \item \textbf{answers}: the answer related to the query based on the text informations.
    \item \textbf{passages}: contains another dictionary where we can find the complete corpus of the text and each passage that composes it.
    \item \textbf{query}: it is the question asked.
\end{itemize}
Since we are interested in the ranking of the documents, we have used the SimpleSearcher from pyserini \cite{pyserini}, in order to obtain the most relevant 1000 documents. 
The pre-processing applied to the dataset is explained in the following subsections.
\subsection{Tokenization}
Starting from the dataset, we have computed the maximum length of the inputs of the encoder (1797) and decoder (4), which will be useful during the tokenization process. We have used the pretrained tokenizer from the small version of the T5 model (reference). Our tokenized dataset is composed only by the following parts:
\begin{itemize}
    \item \textbf{Query}: tokenized version of the original query
    \item \textbf{Query and Corpus}: tokenized input text, which is composed by the concatenation of the query and the corpus
    \item \textbf{Document IDs}: tokenized version of the identificator of each document
    \item \textbf{Ranked Document IDs}: tokenized version of the ranked list of the first 1000 document ids
\end{itemize}
\subsection{DSI Multi-Generation}
\subsection{Data Augmentation}