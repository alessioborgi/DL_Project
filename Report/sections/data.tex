In our work, we have used the first version of the MS Marco Dataset (reference bib), which is composed by 100k real Bing questions and human generated answers. The dataset is already partitioned into Training (82326 samples), Validation (10047 samples) and Test (9650 samples). Each partition is organized as a dictionary where the most important keys are the following:
\begin{itemize}
    \item \textbf{answers}: the answer related to the query based on the text informations.
    \item \textbf{passages}: contains another dictionary where we can find the complete corpus of the text and each passage that composes it.
    \item \textbf{query}: it is the question asked.
\end{itemize}
Since we are interested in the ranking of the documents, we have used the SimpleSearcher from pyserini \cite{pyserini}, in order to obtain the most relevant 1000 documents. 
The pre-processing applied to the dataset is explained in the following subsections.

Starting from the dataset, we have computed the maximum length of the inputs of the encoder (1797) and decoder (4), which will be useful during the tokenization process. We have used the pretrained tokenizer from the small version of the T5 model (reference). Our tokenized dataset is composed only by the following parts:
\begin{itemize}
    \item \textbf{Query}: tokenized version of the original query
    \item \textbf{Query and Corpus}: tokenized input text, which is composed by the concatenation of the query and the corpus
    \item \textbf{Document IDs}: tokenized version of the identificator of each document
    \item \textbf{Ranked Document IDs}: tokenized version of the ranked list of the first 1000 document ids
\end{itemize}
\subsection{DSI Multi-Generation}
In this subsection we have described the procedure to generate semantically structured document ids, which are characterized by the associations between queries and standard document ids. In other words, the docid should be able to capture some informations related to the semantics of the associated document. To do this, we have followed the algorithm provide by (reference ...)

\begin{algorithm}[H]
    \caption{Generating Semantically Structured Identifiers}
    \label{alg:semanticids}
    \begin{algorithmic}[1]
    \Require Document embeddings $X_{1:N}$, where $X_i \in \mathbb{R}^d$ generated by a small 8-layer BERT model with $c=100$
    \Ensure Corresponding docid strings $J_{1:N}$
    \Function{GENERATE\_SEMANTIC\_IDS}{$X_{1:N}$}
        \State $C_{1:10} \gets \Call{Cluster}{X_{1:N},\, k=10}$ \# k-means clustering
        \State $J \gets$ empty list
        \For{$i \gets 0$ to $9$}
            \State $J_{\text{current}} \gets [i] \times |C_{i+1}|$
            \If{$|C_{i+1}| > c$} \# recursion if there are more than c documents
                \State $J_{\text{rest}} \gets \Call{GENERATE\_SEMANTIC\_IDS}{C_{i+1}}$
            \Else
                \State $J_{\text{rest}} \gets [0,\dots,|C_{i+1}| - 1]$ \# assign arbitrary number from 0 to $c-1$
            \EndIf
            \State $J_{\text{cluster}} \gets \Call{elementwise\_Str\_Concat}{J_{\text{current}},\,J_{\text{rest}}}$
            \State $J \gets J.\Call{append\_elements}{J_{\text{cluster}}}$ \# Append all elements of $J_{\text{cluster}}$ to $J$
        \EndFor
        \State $J \gets \Call{reorder\_to\_Original}{J,\,X_{1:N},\,C_{1:10}}$
        \State \Return $J$
    \EndFunction
    \end{algorithmic}
    \end{algorithm}
After this procedure we have followed (reference understanding ...) to create the pseudo-queries, which are new queries generated by a model that takes in input the corpus of the documents.
\begin{align}
    \begin{cases}
        \mathcal{U} = \mathcal{O} \bigcup \mathcal{P} \\
            \mathcal{O} = \bigcup_i \mathcal O_i = \bigcup_i \{ d_i^1, d_i^2, \cdots, d_i^m \} \\
            \mathcal{P} = \bigcup_i \mathcal P_i = \bigcup_i \{ pq_i^1, pq_i^2, \cdots, pq_i^m \}
    \end{cases}
\end{align}
\subsection{Data Augmentation}

\input{sections/augmentation.tex}
